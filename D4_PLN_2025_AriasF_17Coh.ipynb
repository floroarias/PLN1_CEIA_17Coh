{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92427dcd0dbe4cb9bae8b6866313cbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Pregunta:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_42378ca20ebd4d12b8652ff2c84b9d5a",
            "placeholder": "Escribe tu pregunta aquí",
            "style": "IPY_MODEL_78659f0940544b4c8c1b4cae77f0aae5",
            "value": "Francia tomó el control de Argelia en 1830 pero comenzó a reconstruir seriamente su imperio mundial después de 1850, concentrándose principalmente en el norte y el oeste de África, así como el sureste asiático, con otras conquistas en el centro y el este de África, y en el sur del Pacífico. Los republicanos, al principio hostiles al imperio, solo se volvieron solidarios cuando Alemania comenzó a construir su propio imperio colonial. A medida que se desarrollaba, el nuevo imperio asumió funciones de comercio con Francia, suministrando materias primas y comprando artículos manufacturados, además de dar prestigio a la madre patria y difundir la civilización y la lengua francesas, así como el catolicismo. También proporcionó mano de obra esencial en ambas guerras mundiales. ¿En qué se centraron los esfuerzos de Francia para reconstruir su imperio?"
          }
        },
        "42378ca20ebd4d12b8652ff2c84b9d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78659f0940544b4c8c1b4cae77f0aae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44309d13e98641949ad8b8429a5227ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Enviar",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a373b8c9207b4675a23d338da707e65f",
            "style": "IPY_MODEL_6fc93554dd154c7a842302e1a78afa97",
            "tooltip": ""
          }
        },
        "a373b8c9207b4675a23d338da707e65f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc93554dd154c7a842302e1a78afa97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "08f73e788faa45f1b8482bdb598884a3": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_89202ee8a21144209c23dafc1d5801f6",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Bot: la desobediencia de la pobreza\n"
                ]
              }
            ]
          }
        },
        "89202ee8a21144209c23dafc1d5801f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafío 4\n",
        "## Construir un QA Bot basado en el ejemplo del traductor pero con un dataset QA."
      ],
      "metadata": {
        "id": "BOw-ZA3fL1FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Gestionar versiones para evitar incompatibilidades\n",
        "#!pip uninstall -y numpy scipy tensorflow ml-dtypes\n"
      ],
      "metadata": {
        "id": "zGJZhjL6ZimK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099018aa-cad8-419b-d6af-34c46a4bab91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.1\n",
            "Uninstalling numpy-1.26.1:\n",
            "  Successfully uninstalled numpy-1.26.1\n",
            "Found existing installation: scipy 1.13.1\n",
            "Uninstalling scipy-1.13.1:\n",
            "  Successfully uninstalled scipy-1.13.1\n",
            "Found existing installation: tensorflow 2.19.0\n",
            "Uninstalling tensorflow-2.19.0:\n",
            "  Successfully uninstalled tensorflow-2.19.0\n",
            "Found existing installation: ml_dtypes 0.5.1\n",
            "Uninstalling ml_dtypes-0.5.1:\n",
            "  Successfully uninstalled ml_dtypes-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos"
      ],
      "metadata": {
        "id": "Xalv9_FXaXj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar HF Datasets\n",
        "!pip install --quiet datasets\n",
        "#!pip install --upgrade --force-reinstall pandas numpy scipy\n",
        "\n",
        "# Importar\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Cargar XQuAD-es, use split='validation'\n",
        "ds = load_dataset(\"xquad\", \"xquad.es\", split=\"validation\")\n",
        "\n",
        "# descarga directa (aprox. 6 GB descomprimido)\n",
        "!wget -c https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
        "!gunzip cc.es.300.vec.gz"
      ],
      "metadata": {
        "id": "w46GsspaZv7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ec8b01-d696-4a84-cefc-87423c7eea2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-26 19:05:20--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.170.152.30, 3.170.152.69, 3.170.152.93, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.170.152.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "gzip: cc.es.300.vec already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_path = 'cc.es.300.vec'\n",
        "# Import KeyedVectors\n",
        "#from gensim.models import KeyedVectors\n",
        "#FT_VEC = KeyedVectors.load_word2vec_format('cc.es.300.vec')\n",
        "from gensim.models import KeyedVectors\n",
        "fasttext = KeyedVectors.load_word2vec_format(vec_path, binary=False, limit=100_000)"
      ],
      "metadata": {
        "id": "O86ykcCOOYRE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports y funciones auxiliares"
      ],
      "metadata": {
        "id": "aaZeRSY7bFjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.preprocessing.text     import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "\n",
        "def clean_text(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"[^a-z0-9áéíóúñü¿¡ ]+\", \"\", s)\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "1-sDeewnZ9qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbaf9e7-551f-4075-ea46-52b0e9f4b882"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga y preprocesamiento de datos"
      ],
      "metadata": {
        "id": "0XOpCZzHaUIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar listas de question/answer\n",
        "\n",
        "# Concatenamos context + pregunta como entrada\n",
        "questions = []\n",
        "answers   = []\n",
        "for ex in ds:\n",
        "    context = ex[\"context\"]\n",
        "    q       = ex[\"question\"]\n",
        "    ans_txt = ex[\"answers\"][\"text\"][0]   # tomamos la primera respuesta\n",
        "    questions.append(clean_text(context + \" \" + q))\n",
        "    answers.append( \"<start> \" + clean_text(ans_txt) + \" <end>\" )\n"
      ],
      "metadata": {
        "id": "RTcgt_O9aClr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenización y secuencias"
      ],
      "metadata": {
        "id": "OnriLFqEaPK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 8000\n",
        "MAX_LEN = 25\n",
        "\n",
        "# Encoder\n",
        "tokenizer_enc = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<unk>')\n",
        "tokenizer_enc.fit_on_texts(questions)\n",
        "enc_seqs = tokenizer_enc.texts_to_sequences(questions)\n",
        "pad_questions = pad_sequences(enc_seqs, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# Decoder\n",
        "tokenizer_dec = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<unk>')\n",
        "tokenizer_dec.fit_on_texts(answers)\n",
        "dec_seqs = tokenizer_dec.texts_to_sequences(answers)\n",
        "pad_answers = pad_sequences(dec_seqs, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "decoder_input_data = pad_answers[:, :-1]\n",
        "decoder_target_data = np.expand_dims(pad_answers[:, 1:], -1)\n",
        "\n",
        "vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer_enc.word_index) + 1)\n",
        "vocab_size_dec = min(MAX_VOCAB_SIZE, len(tokenizer_dec.word_index) + 1)\n"
      ],
      "metadata": {
        "id": "Jskn_wYXaKzq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar FastText y crear matrices de embedding"
      ],
      "metadata": {
        "id": "4NOIRxGHbdCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 300\n",
        "def build_embedding_matrix(tokenizer, vocab_size):\n",
        "    matrix = np.zeros((vocab_size, EMBED_DIM))\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "        if idx < vocab_size and word in fasttext:\n",
        "            matrix[idx] = fasttext[word]\n",
        "    return matrix\n",
        "\n",
        "embedding_matrix_enc = build_embedding_matrix(tokenizer_enc, vocab_size)\n",
        "embedding_matrix_dec = build_embedding_matrix(tokenizer_dec, vocab_size_dec)"
      ],
      "metadata": {
        "id": "fCkvq-z1beV1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir y compilar el modelo Seq2Seq"
      ],
      "metadata": {
        "id": "u8hLqAnebmRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Masking\n",
        "\n",
        "n_units = 256\n",
        "lstm_dropout = 0.2\n",
        "\n",
        "from tensorflow.keras.layers import AdditiveAttention, Concatenate\n",
        "\n",
        "# — Encoder —\n",
        "encoder_inputs = Input(shape=(MAX_LEN,), name='encoder_inputs')\n",
        "enc_emb = Embedding(vocab_size, EMBED_DIM, weights=[embedding_matrix_enc],\n",
        "                    trainable=False, name='encoder_embedding')(encoder_inputs)\n",
        "enc_masked    = Masking(mask_value=0.0, name='encoder_masking')(enc_emb)\n",
        "enc_outputs, state_h, state_c = LSTM(\n",
        "    n_units, return_sequences=True, return_state=True, name='encoder_lstm'\n",
        ")(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# — Decoder —\n",
        "decoder_inputs = Input(shape=(MAX_LEN-1,), name='decoder_inputs')\n",
        "dec_emb = Embedding(vocab_size_dec, EMBED_DIM, weights=[embedding_matrix_dec],\n",
        "                    trainable=False, name='decoder_embedding')(decoder_inputs)\n",
        "dec_masked     = Masking(mask_value=0.0, name='decoder_masking')(dec_emb)\n",
        "dec_outputs, _, _ = LSTM(\n",
        "    n_units, return_sequences=True, return_state=True, name='decoder_lstm'\n",
        ")(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# — Attention —\n",
        "attn = AdditiveAttention(name='attention_layer')(\n",
        "    [dec_outputs, enc_outputs]\n",
        ")\n",
        "# Combinas la salida del LSTM del decoder con el vector de contexto\n",
        "dec_concat = Concatenate(axis=-1, name='concat_layer')([dec_outputs, attn])\n",
        "\n",
        "# — Output —\n",
        "decoder_outputs = Dense(vocab_size_dec, activation='softmax',\n",
        "                        name='decoder_dense')(dec_concat)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "nREgFzUlbn15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "5b79cd90-3eb2-4a93-aa17-ca906f2d8b53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m2,400,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │    \u001b[38;5;34m631,800\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m570,368\u001b[0m │ decoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m2106\u001b[0m)  │  \u001b[38;5;34m1,080,378\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">631,800</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> │ decoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2106</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,080,378</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,253,170\u001b[0m (20.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,253,170</span> (20.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,221,370\u001b[0m (8.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,221,370</span> (8.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,031,800\u001b[0m (11.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,031,800</span> (11.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "Jp0WUDuGb2E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 70\n",
        "batch_size = 64\n",
        "\n",
        "model.fit(\n",
        "    [pad_questions, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "Yb4l5Lbkb41U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1003f8c1-1405-4cde-e2bb-da8bae9be65d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6480 - loss: 5.0343 - val_accuracy: 0.7992 - val_loss: 1.5197\n",
            "Epoch 2/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8372 - loss: 1.2177 - val_accuracy: 0.8018 - val_loss: 1.5058\n",
            "Epoch 3/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8378 - loss: 1.1932 - val_accuracy: 0.8048 - val_loss: 1.4898\n",
            "Epoch 4/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8330 - loss: 1.2191 - val_accuracy: 0.8129 - val_loss: 1.4304\n",
            "Epoch 5/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8430 - loss: 1.2108 - val_accuracy: 0.8102 - val_loss: 1.4236\n",
            "Epoch 6/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8498 - loss: 1.0712 - val_accuracy: 0.8167 - val_loss: 1.3796\n",
            "Epoch 7/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8518 - loss: 1.0596 - val_accuracy: 0.8244 - val_loss: 1.3342\n",
            "Epoch 8/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8471 - loss: 1.0827 - val_accuracy: 0.8302 - val_loss: 1.3214\n",
            "Epoch 9/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8672 - loss: 0.9586 - val_accuracy: 0.8342 - val_loss: 1.3120\n",
            "Epoch 10/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8629 - loss: 0.9926 - val_accuracy: 0.8274 - val_loss: 1.3226\n",
            "Epoch 11/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8597 - loss: 1.0009 - val_accuracy: 0.8339 - val_loss: 1.3126\n",
            "Epoch 12/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8677 - loss: 0.9443 - val_accuracy: 0.8328 - val_loss: 1.3094\n",
            "Epoch 13/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8637 - loss: 0.9618 - val_accuracy: 0.8328 - val_loss: 1.3138\n",
            "Epoch 14/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8641 - loss: 0.9568 - val_accuracy: 0.8328 - val_loss: 1.3104\n",
            "Epoch 15/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8609 - loss: 0.9675 - val_accuracy: 0.8326 - val_loss: 1.3169\n",
            "Epoch 16/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8627 - loss: 0.9473 - val_accuracy: 0.8328 - val_loss: 1.3157\n",
            "Epoch 17/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8627 - loss: 0.9553 - val_accuracy: 0.8342 - val_loss: 1.3208\n",
            "Epoch 18/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 0.9671 - val_accuracy: 0.8298 - val_loss: 1.3530\n",
            "Epoch 19/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8696 - loss: 0.8999 - val_accuracy: 0.8298 - val_loss: 1.3531\n",
            "Epoch 20/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8642 - loss: 0.9211 - val_accuracy: 0.8248 - val_loss: 1.4153\n",
            "Epoch 21/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8673 - loss: 0.9010 - val_accuracy: 0.8225 - val_loss: 1.4331\n",
            "Epoch 22/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8634 - loss: 0.9217 - val_accuracy: 0.6017 - val_loss: 2.3971\n",
            "Epoch 23/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8159 - loss: 1.1418 - val_accuracy: 0.8218 - val_loss: 1.4315\n",
            "Epoch 24/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8716 - loss: 0.8803 - val_accuracy: 0.8234 - val_loss: 1.4319\n",
            "Epoch 25/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8661 - loss: 0.8975 - val_accuracy: 0.8225 - val_loss: 1.4406\n",
            "Epoch 26/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8620 - loss: 0.9224 - val_accuracy: 0.8353 - val_loss: 1.3315\n",
            "Epoch 27/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8634 - loss: 0.9066 - val_accuracy: 0.8321 - val_loss: 1.3778\n",
            "Epoch 28/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8647 - loss: 0.8998 - val_accuracy: 0.8255 - val_loss: 1.4458\n",
            "Epoch 29/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8580 - loss: 0.9329 - val_accuracy: 0.8244 - val_loss: 1.4656\n",
            "Epoch 30/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8678 - loss: 0.8733 - val_accuracy: 0.8381 - val_loss: 1.3469\n",
            "Epoch 31/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8709 - loss: 0.8577 - val_accuracy: 0.8368 - val_loss: 1.3432\n",
            "Epoch 32/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8661 - loss: 0.8820 - val_accuracy: 0.8368 - val_loss: 1.3583\n",
            "Epoch 33/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8651 - loss: 0.8810 - val_accuracy: 0.8367 - val_loss: 1.3640\n",
            "Epoch 34/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8677 - loss: 0.8661 - val_accuracy: 0.8337 - val_loss: 1.3806\n",
            "Epoch 35/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8653 - loss: 0.8703 - val_accuracy: 0.8349 - val_loss: 1.3845\n",
            "Epoch 36/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8676 - loss: 0.8594 - val_accuracy: 0.8309 - val_loss: 1.4366\n",
            "Epoch 37/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8684 - loss: 0.8488 - val_accuracy: 0.8267 - val_loss: 1.4610\n",
            "Epoch 38/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8684 - loss: 0.8386 - val_accuracy: 0.8276 - val_loss: 1.4645\n",
            "Epoch 39/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.8640 - val_accuracy: 0.8267 - val_loss: 1.4697\n",
            "Epoch 40/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8644 - loss: 0.8621 - val_accuracy: 0.8374 - val_loss: 1.3699\n",
            "Epoch 41/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8678 - loss: 0.8359 - val_accuracy: 0.8284 - val_loss: 1.4667\n",
            "Epoch 42/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8661 - loss: 0.8393 - val_accuracy: 0.8269 - val_loss: 1.4787\n",
            "Epoch 43/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8668 - loss: 0.8386 - val_accuracy: 0.8298 - val_loss: 1.4670\n",
            "Epoch 44/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8709 - loss: 0.8133 - val_accuracy: 0.8346 - val_loss: 1.4122\n",
            "Epoch 45/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8629 - loss: 0.8521 - val_accuracy: 0.8291 - val_loss: 1.4823\n",
            "Epoch 46/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8643 - loss: 0.8416 - val_accuracy: 0.8302 - val_loss: 1.4773\n",
            "Epoch 47/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8700 - loss: 0.8112 - val_accuracy: 0.8361 - val_loss: 1.3910\n",
            "Epoch 48/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8705 - loss: 0.8063 - val_accuracy: 0.8365 - val_loss: 1.3937\n",
            "Epoch 49/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8672 - loss: 0.8172 - val_accuracy: 0.8372 - val_loss: 1.3943\n",
            "Epoch 50/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8663 - loss: 0.8246 - val_accuracy: 0.8374 - val_loss: 1.3940\n",
            "Epoch 51/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8689 - loss: 0.8042 - val_accuracy: 0.8374 - val_loss: 1.4062\n",
            "Epoch 52/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8677 - loss: 0.8159 - val_accuracy: 0.8382 - val_loss: 1.4046\n",
            "Epoch 53/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8747 - loss: 0.7680 - val_accuracy: 0.8367 - val_loss: 1.3956\n",
            "Epoch 54/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8691 - loss: 0.8003 - val_accuracy: 0.8388 - val_loss: 1.3981\n",
            "Epoch 55/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8682 - loss: 0.7952 - val_accuracy: 0.8375 - val_loss: 1.4039\n",
            "Epoch 56/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8654 - loss: 0.8128 - val_accuracy: 0.8374 - val_loss: 1.4078\n",
            "Epoch 57/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8660 - loss: 0.8061 - val_accuracy: 0.8381 - val_loss: 1.4041\n",
            "Epoch 58/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8707 - loss: 0.7856 - val_accuracy: 0.8379 - val_loss: 1.4071\n",
            "Epoch 59/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8672 - loss: 0.7952 - val_accuracy: 0.8379 - val_loss: 1.4157\n",
            "Epoch 60/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8654 - loss: 0.8046 - val_accuracy: 0.8367 - val_loss: 1.4152\n",
            "Epoch 61/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8688 - loss: 0.7797 - val_accuracy: 0.8381 - val_loss: 1.4242\n",
            "Epoch 62/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8745 - loss: 0.7595 - val_accuracy: 0.8377 - val_loss: 1.4191\n",
            "Epoch 63/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8656 - loss: 0.7959 - val_accuracy: 0.8356 - val_loss: 1.4370\n",
            "Epoch 64/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8636 - loss: 0.7987 - val_accuracy: 0.8361 - val_loss: 1.4415\n",
            "Epoch 65/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8694 - loss: 0.7701 - val_accuracy: 0.8367 - val_loss: 1.4318\n",
            "Epoch 66/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8695 - loss: 0.7714 - val_accuracy: 0.8375 - val_loss: 1.4366\n",
            "Epoch 67/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8580 - loss: 0.9296 - val_accuracy: 0.8377 - val_loss: 1.4419\n",
            "Epoch 68/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8719 - loss: 0.7574 - val_accuracy: 0.8370 - val_loss: 1.4452\n",
            "Epoch 69/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8709 - loss: 0.7639 - val_accuracy: 0.8377 - val_loss: 1.4385\n",
            "Epoch 70/70\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8628 - loss: 0.7858 - val_accuracy: 0.8379 - val_loss: 1.4395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5df41aef50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar modelo y tokenizers"
      ],
      "metadata": {
        "id": "n1UTCxiQcF88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('qa_seq2seq_fasttext.h5')\n",
        "with open('tokenizer_enc.pkl','wb') as f: pickle.dump(tokenizer_enc, f)\n",
        "with open('tokenizer_dec.pkl','wb') as f: pickle.dump(tokenizer_dec, f)"
      ],
      "metadata": {
        "id": "zWAWxwttcIWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece624a8-bc9d-4d45-e7c7-741f4d69d8a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar modelos de inferencia"
      ],
      "metadata": {
        "id": "t0lNxxAkcL0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# 1) Carga el modelo entrenado (sin custom_objects si usaste Masking)\n",
        "model = load_model('qa_seq2seq_fasttext.h5', compile=False)\n",
        "\n",
        "# 2) Reconstruir encoder_model (ahora devuelve outputs + estados)\n",
        "encoder_inputs = model.input[0]  # la entrada de encoder\n",
        "encoder_lstm = model.get_layer('encoder_lstm')\n",
        "# enc_outputs: secuencia completa, state_h y state_c\n",
        "enc_outputs, state_h_enc, state_c_enc = encoder_lstm.output\n",
        "encoder_model = Model(\n",
        "    inputs=encoder_inputs,\n",
        "    outputs=[enc_outputs, state_h_enc, state_c_enc]\n",
        ")\n",
        "\n",
        "# 3) Reconstruir decoder_model con atención\n",
        "# a) crear placeholders para las 4 entradas\n",
        "decoder_inputs      = model.input[1]  # token actual\n",
        "enc_outputs_input   = Input(shape=enc_outputs.shape[1:], name='enc_out_in')\n",
        "decoder_state_h_in  = Input(shape=state_h_enc.shape[1:], name='dec_h_in')\n",
        "decoder_state_c_in  = Input(shape=state_c_enc.shape[1:], name='dec_c_in')\n",
        "dec_states_inputs   = [decoder_state_h_in, decoder_state_c_in]\n",
        "\n",
        "# b) capas originales reutilizadas\n",
        "dec_emb_layer   = model.get_layer('decoder_embedding')\n",
        "dec_lstm_layer  = model.get_layer('decoder_lstm')\n",
        "attn_layer      = model.get_layer('attention_layer')    # AdditiveAttention\n",
        "concat_layer    = model.get_layer('concat_layer')       # Concatenate\n",
        "dense_layer     = model.get_layer('decoder_dense')\n",
        "\n",
        "# c) paso a paso\n",
        "dec_emb2     = dec_emb_layer(decoder_inputs)\n",
        "dec_out2, h2, c2 = dec_lstm_layer(\n",
        "    dec_emb2,\n",
        "    initial_state=dec_states_inputs\n",
        ")\n",
        "# aplicar atención: query=dec_out2, value=enc_outputs_input\n",
        "attn_out     = attn_layer([dec_out2, enc_outputs_input])\n",
        "dec_concat2  = concat_layer([dec_out2, attn_out])\n",
        "dec_preds    = dense_layer(dec_concat2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    inputs=[decoder_inputs, enc_outputs_input] + dec_states_inputs,\n",
        "    outputs=[dec_preds, h2, c2]\n",
        ")"
      ],
      "metadata": {
        "id": "3ZoYKnxucOE2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función decode_sequence y pruebas"
      ],
      "metadata": {
        "id": "0bqmkruhcRUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Función de decodificación mejorada\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "trained_maxlen = model.input_shape[0][1]\n",
        "\n",
        "# 4) Función de inferencia actualizada:\n",
        "def decode_sequence(input_text):\n",
        "    # a) prepara la secuencia de entrada como antes...\n",
        "    seq = tokenizer_enc.texts_to_sequences([clean_text(input_text)])\n",
        "    seq = pad_sequences(seq, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "    # b) obtené enc_outputs y estados\n",
        "    enc_outs, h, c = encoder_model.predict(seq)\n",
        "\n",
        "    # c) iniciás con <start>\n",
        "    #start_idx   = tokenizer_dec.word_index['<start>']\n",
        "    # 1) Intenta varios nombres comunes de token start\n",
        "    candidates = ['<start>', 'start', 'startseq', '<startseq>']\n",
        "    start_idx = None\n",
        "    for t in candidates:\n",
        "        if t in tokenizer_dec.word_index:\n",
        "            start_idx = tokenizer_dec.word_index[t]\n",
        "            break\n",
        "\n",
        "    # 2) Si no hay ninguno, levanta un error informativo\n",
        "    if start_idx is None:\n",
        "        valid = list(tokenizer_dec.word_index.keys())[:20]\n",
        "        raise KeyError(\n",
        "            f\"No hallé ningún token de inicio en tokenizer_dec.word_index. \"\n",
        "            f\"Probables claves del tokenizer (primeras 20): {valid}\"\n",
        "        )\n",
        "    target_seq  = np.array([[start_idx]])\n",
        "    decoded     = []\n",
        "    prev_word   = None\n",
        "\n",
        "    for _ in range(MAX_LEN):\n",
        "      # LLAMADO CON LAS 4 entradas\n",
        "      preds, h, c = decoder_model.predict([target_seq, enc_outs, h, c])\n",
        "\n",
        "      probs       = preds[0, -1, :]\n",
        "      sampled_idx = np.argmax(probs)\n",
        "      sampled_word = tokenizer_dec.index_word.get(sampled_idx, '<unk>')\n",
        "\n",
        "      if sampled_word in ('<end>','end') or sampled_word==prev_word:\n",
        "        break\n",
        "\n",
        "      decoded.append(sampled_word)\n",
        "      prev_word = sampled_word\n",
        "\n",
        "      target_seq = np.array([[sampled_idx]])\n",
        "\n",
        "    return ' '.join(decoded)"
      ],
      "metadata": {
        "id": "poS3I5YscgSx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Muestra 5 ejemplos aleatorios del dataset\n",
        "for ex in ds.shuffle(seed=123).select(range(5)):\n",
        "    context = ex[\"context\"]\n",
        "    question = ex[\"question\"]\n",
        "    gold_answer = ex[\"answers\"][\"text\"][0]\n",
        "    print(\"Contexto:\", context)\n",
        "    print(\"Pregunta:\", question)\n",
        "    print(\"Respuesta esperada:\", gold_answer)\n",
        "    print(\"Respuesta del bot:\", decode_sequence(context + \" \" + question))\n",
        "    print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwgLaOJdqCDo",
        "outputId": "ec0b1ba6-dad1-41d6-8a52-99ad75d3121d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contexto: El Partido Laborista Australiano (ALP), de centro-izquierda, el Partido Liberal de Australia, de centro-derecha, el Partido Nacional de Australia, del medio rural, y los Verdes australianos, ecologistas, son los principales partidos políticos de Victoria. Tradicionalmente, los laboristas son más fuertes en la periferia oeste y norte de clase trabajadora de Melbourne y en las ciudades de Ballarat, Bendigo y Geelong, situadas en la región. El principal apoyo a los liberales radica en la periferia este y exterior de Melbourne, más acomodada, y en algunos centros rurales y regionales. Los nacionales tienen más apoyo en las áreas regionales rurales del noroeste y el este de Victoria. Los Verdes, que ganaron sus primeros escaños en la cámara baja en 2014, tienen más apoyo en el centro de Melbourne.\n",
            "Pregunta: ¿Qué partido político tiene más apoyo en la periferia de clase trabajadora de Melbourne?\n",
            "Respuesta esperada: Partido Laborista Australiano\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Respuesta del bot: la\n",
            "--------------------------------------------------------------------------------\n",
            "Contexto: Francia tomó el control de Argelia en 1830 pero comenzó a reconstruir seriamente su imperio mundial después de 1850, concentrándose principalmente en el norte y el oeste de África, así como el sureste asiático, con otras conquistas en el centro y el este de África, y en el sur del Pacífico. Los republicanos, al principio hostiles al imperio, solo se volvieron solidarios cuando Alemania comenzó a construir su propio imperio colonial. A medida que se desarrollaba, el nuevo imperio asumió funciones de comercio con Francia, suministrando materias primas y comprando artículos manufacturados, además de dar prestigio a la madre patria y difundir la civilización y la lengua francesas, así como el catolicismo. También proporcionó mano de obra esencial en ambas guerras mundiales.\n",
            "Pregunta: ¿En qué se centraron los esfuerzos de Francia para reconstruir su imperio?\n",
            "Respuesta esperada: el norte y el oeste de África\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Respuesta del bot: la desobediencia de la pobreza\n",
            "--------------------------------------------------------------------------------\n",
            "Contexto: El 28 de febrero de 2008, Kibaki y Odinga firmaron un acuerdo sobre la formación de un gobierno de coalición en el que Odinga se convertiría en el segundo primer ministro de Kenia. Según el acuerdo, el presidente nombraría ministros del gabinete de las facciones PNU y ODM dependiendo de la fuerza de cada partido en el parlamento. El acuerdo estipulaba que el gabinete incluiría un vicepresidente y dos viceprimeros ministros. Después de los debates, el parlamento aprobó que la coalición se mantendría hasta el final del parlamento actual o hasta que alguna de las partes se retirara.\n",
            "Pregunta: ¿De dónde nombró el presidente a los miembros del gabinete?\n",
            "Respuesta esperada: PNU y ODM\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Respuesta del bot: la desobediencia de la pobreza\n",
            "--------------------------------------------------------------------------------\n",
            "Contexto: El proyecto debe cumplir con los requisitos del código de construcción y zonificación. Construir un proyecto que no se ajuste a los códigos no beneficia al propietario. Algunos requisitos legales provienen de consideraciones de malum in se, o el deseo de prevenir cosas que son indiscutiblemente malas, como derrumbes o explosiones de puentes. Otros requisitos legales provienen de consideraciones de malum prohibitum, o cosas que son una cuestión de costumbre o expectativa, como aislar negocios a un distrito de negocios y residencias a un distrito residencial. Un abogado puede solicitar cambios o exenciones en la ley que rige el terreno donde se construirá el edificio, ya sea argumentando que una regla es inaplicable (el diseño del puente no causará un colapso), o que la costumbre ya no es necesaria (la aceptación de los espacios de trabajo en viviendas ha crecido en la comunidad).\n",
            "Pregunta: ¿Qué es el malum in se?\n",
            "Respuesta esperada: el deseo de prevenir cosas que son indiscutiblemente malas\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Respuesta del bot: la\n",
            "--------------------------------------------------------------------------------\n",
            "Contexto: El V&A tiene sus orígenes en la Gran Exposición de 1851, con la que Henry Cole, el primer director del museo, participó en la planificación; inicialmente fue conocido como el Museo de Manufacturas, inaugurado en mayo de 1852 en Marlborough House, pero en septiembre ya estaba transferido a Somerset House. En esta etapa las colecciones abarcaban tanto el arte aplicado como la ciencia. Varias de las piezas de la exposición fueron adquiridas para formar el núcleo de la colección. En febrero de 1854 se iniciaron las conversaciones para trasladar el museo al sitio actual y se le cambió el nombre por el del museo de South Kensington. En 1855, el arquitecto alemán Gottfried Semper, a petición de Cole, realizó un diseño para el museo, pero fue rechazado por la Junta de Comercio por ser demasiado caro. El sitio fue ocupado por la Brompton Park House, que se amplió para incluir las primeras salas de refrigerio inauguradas en 1857, siendo el museo el primero en el mundo en ofrecer este tipo de instalaciones.\n",
            "Pregunta: ¿Cómo se llamaba originalmente el museo?\n",
            "Respuesta esperada: Museo de Manufacturas\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Respuesta del bot: la desobediencia de la pobreza\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba interactiva usando ipywidgets"
      ],
      "metadata": {
        "id": "PLA-DM_zdVrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet ipywidgets\n",
        "from ipywidgets import Text, Button, Output\n",
        "from IPython.display import display\n",
        "\n",
        "# Creamos los widgets\n",
        "caja_pregunta = Text(placeholder='Escribe tu pregunta aquí', description='Pregunta:')\n",
        "boton = Button(description='Enviar')\n",
        "salida = Output()\n",
        "\n",
        "# Función que se ejecuta al hacer clic\n",
        "def on_click(b):\n",
        "    with salida:\n",
        "        salida.clear_output()\n",
        "        q = caja_pregunta.value\n",
        "        a = decode_sequence(q)\n",
        "        print(\"Bot:\", a)\n",
        "\n",
        "boton.on_click(on_click)\n",
        "display(caja_pregunta, boton, salida)"
      ],
      "metadata": {
        "id": "FbAkuLdRdT_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "92427dcd0dbe4cb9bae8b6866313cbe7",
            "42378ca20ebd4d12b8652ff2c84b9d5a",
            "78659f0940544b4c8c1b4cae77f0aae5",
            "44309d13e98641949ad8b8429a5227ca",
            "a373b8c9207b4675a23d338da707e65f",
            "6fc93554dd154c7a842302e1a78afa97",
            "08f73e788faa45f1b8482bdb598884a3",
            "89202ee8a21144209c23dafc1d5801f6"
          ]
        },
        "outputId": "b0ff4e06-35d1-4b97-cd07-4c2298b87e7d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Pregunta:', placeholder='Escribe tu pregunta aquí')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92427dcd0dbe4cb9bae8b6866313cbe7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Enviar', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44309d13e98641949ad8b8429a5227ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08f73e788faa45f1b8482bdb598884a3"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}